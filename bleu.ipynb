{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: torchvision 0.15.1 has requirement torch==2.0.0, but you'll have torch 1.13.1 which is incompatible.\n",
      "WARNING: You are using pip version 19.2.3, however version 23.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 19.2.3, however version 23.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading https://files.pythonhosted.org/packages/20/9c/f07bd70d128fdb107bc02a0c702b9058b4fe147d0ba67b5a0f4c3cf15a54/sentence-transformers-2.2.2.tar.gz (85kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (4.26.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (1.13.1)\n",
      "Collecting torchvision (from sentence_transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/2f/bfd590bf3bfd4cb326cdd6bd81600f77e5eaddad718f1dc87e2ca9312582/torchvision-0.15.1-cp38-cp38-win_amd64.whl (1.2MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (1.24.2)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/fb/478a0460ae2843dd2fc7a7f9ddcd8bb033ae21eb968df6a8cbe8094a28bc/scikit_learn-1.2.2-cp38-cp38-win_amd64.whl (8.3MB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/32/8e/7f403535ddf826348c9b8417791e28712019962f7e90ff845896d6325d09/scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2MB)\n",
      "Requirement already satisfied: nltk in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence_transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/72/31/92d0ada03abf4d2b98fdaa64f10d760225ac2a9a398c0fd7ba6f3660b17b/sentencepiece-0.1.97-cp38-cp38-win_amd64.whl (1.1MB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anthony pierson\\appdata\\roaming\\python\\python38\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\anthony pierson\\appdata\\roaming\\python\\python38\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (4.5.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->sentence_transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/ba/c4c2a1411561cd9725979115e7450f1367b44997ae1ff29e5845bce92d52/Pillow-9.5.0-cp38-cp38-win_amd64.whl (2.5MB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.4)\n",
      "Installing collected packages: pillow, torchvision, threadpoolctl, scipy, scikit-learn, sentencepiece, sentence-transformers\n",
      "  Running setup.py install for sentence-transformers: started\n",
      "    Running setup.py install for sentence-transformers: finished with status 'done'\n",
      "Successfully installed pillow-9.5.0 scikit-learn-1.2.2 scipy-1.10.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 threadpoolctl-3.1.0 torchvision-0.15.1\n",
      "Collecting sentence_transformers\n",
      "  Using cached https://files.pythonhosted.org/packages/20/9c/f07bd70d128fdb107bc02a0c702b9058b4fe147d0ba67b5a0f4c3cf15a54/sentence-transformers-2.2.2.tar.gz\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (4.26.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (1.24.2)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/fb/478a0460ae2843dd2fc7a7f9ddcd8bb033ae21eb968df6a8cbe8094a28bc/scikit_learn-1.2.2-cp38-cp38-win_amd64.whl\n",
      "Requirement already satisfied: scipy in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence_transformers)\n",
      "  Using cached https://files.pythonhosted.org/packages/72/31/92d0ada03abf4d2b98fdaa64f10d760225ac2a9a398c0fd7ba6f3660b17b/sentencepiece-0.1.97-cp38-cp38-win_amd64.whl\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (0.12.1)\n",
      "Requirement already satisfied: requests in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anthony pierson\\appdata\\roaming\\python\\python38\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\anthony pierson\\appdata\\roaming\\python\\python38\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision->sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.26.14)\n",
      "Installing collected packages: scikit-learn, sentencepiece, sentence-transformers\n",
      "  Running setup.py install for sentence-transformers: started\n",
      "    Running setup.py install for sentence-transformers: finished with status 'done'\n",
      "Successfully installed scikit-learn-1.2.2 sentence-transformers-2.2.2 sentencepiece-0.1.97\n",
      "Requirement already satisfied: nltk in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.8.1)\n",
      "Collecting sentence_transformers\n",
      "  Using cached https://files.pythonhosted.org/packages/20/9c/f07bd70d128fdb107bc02a0c702b9058b4fe147d0ba67b5a0f4c3cf15a54/sentence-transformers-2.2.2.tar.gz\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (4.26.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (1.24.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (0.1.97)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence_transformers) (0.12.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\anthony pierson\\appdata\\roaming\\python\\python38\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anthony pierson\\appdata\\roaming\\python\\python38\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision->sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anthony pierson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.4)\n",
      "Installing collected packages: sentence-transformers\n",
      "  Running setup.py install for sentence-transformers: started\n",
      "    Running setup.py install for sentence-transformers: finished with status 'done'\n",
      "Successfully installed sentence-transformers-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 23.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "from FunctionExtract import core_extractor\n",
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison():\n",
    "    def __init__(this, ref, gen):\n",
    "        this.ref = ref\n",
    "        this.gen = gen\n",
    "\n",
    "    def compareBLEU(this):\n",
    "        refsplit = this.ref.split(\" \")\n",
    "        gensplit = this.gen.split(\" \")\n",
    "        \n",
    "        score = sentence_bleu([refsplit],gensplit)\n",
    "        this.similarity = score\n",
    "        return(score)\n",
    "    \n",
    "    def compareHF(this):\n",
    "        model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        ref_embedding = model.encode(this.ref, convert_to_tensor = True)\n",
    "        gen_embedding = model.encode(this.gen, convert_to_tensor = True)\n",
    "\n",
    "        return(util.pytorch_cos_sim(ref_embedding,gen_embedding)[0][0])\n",
    "\n",
    "class comparisonCorpus():\n",
    "    def __init__(this):\n",
    "        this.comparisonpairs = []\n",
    "\n",
    "    def addComparison(this,comparison):\n",
    "        this.comparisonpairs.append(comparison)\n",
    "    \n",
    "    def generateMetrics(this):\n",
    "        BLEUscores = []\n",
    "        HFscores = []\n",
    "        lengthAnomoly = []\n",
    "        \n",
    "        for comparison in this.comparisonpairs:\n",
    "            BLEUscores.append(comparison.compareBLEU())\n",
    "            HFscores.append(comparison.compareHF())\n",
    "            lengthAnomoly.append(np.abs(len(comparison.ref)-len(comparison.gen)))\n",
    "        \n",
    "        print(\"BLEU similarity metrics for dataset: \")\n",
    "        print(\"Mean: \",np.mean(BLEUscores))\n",
    "        print(\"Median: \",np.median(BLEUscores))\n",
    "        print(\"HF Sentence-Transformer similarity metrics for dataset: \")\n",
    "        print(\"Mean: \",np.mean(HFscores))\n",
    "        print(\"Median: \",np.median(HFscores))\n",
    "        print(\"Length anomoly metrics for dataset: \")\n",
    "        print(\"Mean: \",np.mean(lengthAnomoly))\n",
    "        print(\"Median: \",np.median(lengthAnomoly))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "\n",
    "CODE_START = \"CODE:\\n\"\n",
    "CODE_END = \"CODE_END\"\n",
    "COMMENT_START = \"COMMENT:\\n\"\n",
    "COMMENT_END = \"COMMENT_END\"\n",
    "\n",
    "pairs = []\n",
    "\n",
    "with open(\"train.csv\",\"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    rownumber = 0\n",
    "    for row in reader:\n",
    "        if(rownumber > 0):\n",
    "            cell_contents = \",\".join(row)\n",
    "            #print(\"cell contents: \", cell_contents)\n",
    "            code_start = cell_contents.index(CODE_START)\n",
    "            code_end = cell_contents.index(CODE_END)\n",
    "            comment_start = cell_contents.index(COMMENT_START)\n",
    "            comment_end = cell_contents.index(COMMENT_END)\n",
    "            code = cell_contents[code_start + len(CODE_START):code_end]\n",
    "            comment = cell_contents[comment_start + len(COMMENT_START):comment_end]\n",
    "            pairs.append((code,comment))\n",
    "        rownumber += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1 = comparisonCorpus()\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base-multi-sum')\n",
    "\n",
    "#model = T5ForConditionalGeneration.from_pretrained(\".\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-base-multi-sum\")\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    code = pairs[i][0]\n",
    "    comment = pairs[i][1]\n",
    "\n",
    "    input_ids = tokenizer(code,return_tensors=\"pt\").input_ids\n",
    "    generated_ids = model.generate(input_ids, max_length=512)\n",
    "    gencomment = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    cc1.addComparison(Comparison(comment,gencomment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2 = comparisonCorpus()\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base-multi-sum')\n",
    "\n",
    "#model = T5ForConditionalGeneration.from_pretrained(\".\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\".\")\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    code = pairs[i][0]\n",
    "    comment = pairs[i][1]\n",
    "\n",
    "    input_ids = tokenizer(code,return_tensors=\"pt\").input_ids\n",
    "    generated_ids = model.generate(input_ids, max_length=512)\n",
    "    gencomment = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    cc2.addComparison(Comparison(comment,gencomment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anthony Pierson\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Anthony Pierson\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Anthony Pierson\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 117.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU similarity metrics for dataset: \n",
      "Mean:  0.02856299175538744\n",
      "Median:  9.674272450044849e-239\n",
      "HF Sentence-Transformer similarity metrics for dataset: \n",
      "Mean:  0.44830078\n",
      "Median:  0.40915382\n",
      "Length anomoly metrics for dataset: \n",
      "Mean:  74.9\n",
      "Median:  52.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cc.generateMetrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d4686d9c9b92981dc324bcd939dfa1976a28f1552ffec9a268b1875a02072d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
